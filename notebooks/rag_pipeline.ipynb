{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea21c94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1804b271",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api_key = os.environ.get(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f29322c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading/Reading all the pdf documents\n",
    "\n",
    "from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    \"../data/pdf_files\",\n",
    "    glob=\"**/*.pdf\",\n",
    "    loader_cls=PyPDFLoader\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "len(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "875bf9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 98 chunks\n"
     ]
    }
   ],
   "source": [
    "# Splitting the Texts into Chunks\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "split_texts = text_splitter.split_documents(docs)\n",
    "print(f\"Created {len(split_texts)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b342c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_1584\\2335338193.py:5: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Vector store created with 98 embeddings\n"
     ]
    }
   ],
   "source": [
    "# Embedding the split texts into vectors\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "# Creating the Vector Store (ChromaDB)\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "vectorstores = Chroma.from_documents(\n",
    "    documents=split_texts,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"../data/chroma_db\"\n",
    ")\n",
    "\n",
    "print(f\"Vector store created with {len(split_texts)} embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d5c0b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstores.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3}  # Return top 3 most relevant chunks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf5454f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_1584\\2105759968.py:5: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "# Adding Memory\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    "    output_key=\"answer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2da8f658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Groq LLM (llama-3.3-70b-versatile)\n"
     ]
    }
   ],
   "source": [
    "# Prompting\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are an expert AI assistant specialized in construction tender analysis.\n",
    "\n",
    "Your role is to help analyze tender documents and company capabilities to determine bid feasibility.\n",
    "\n",
    "IMPORTANT RULES:\n",
    "- Answer naturally and conversationally (never say \"according to the document\")\n",
    "- Use the conversation history to understand context and follow-up questions\n",
    "- Be specific with numbers, dates, and requirements\n",
    "- If you don't have enough information, say so clearly\n",
    "- Focus on actionable insights for decision-making\n",
    "- Compare tender requirements against company capabilities when relevant\n",
    "\n",
    "Remember: You're helping a construction company decide whether to bid on projects.\"\"\"),\n",
    "    \n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    \n",
    "    (\"human\", \"\"\"Context information from documents:\n",
    "{context}\n",
    "\n",
    "Question: {question}\"\"\")\n",
    "])\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "groq_llm = ChatGroq(\n",
    "    groq_api_key=groq_api_key,\n",
    "    model_name=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0.1,  # Low temperature for factual responses\n",
    "    max_tokens=1024\n",
    ")\n",
    "\n",
    "print(\"Connected to Groq LLM (llama-3.3-70b-versatile)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b5a8803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build RAG Chain\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "def format_docs(docs):\n",
    "    \"\"\"Format retrieved documents into a single string\"\"\"\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "def get_chat_history(memory):\n",
    "    \"\"\"Extract chat history from memory\"\"\"\n",
    "    return memory.load_memory_variables({}).get(\"chat_history\", [])\n",
    "\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": retriever | format_docs,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"chat_history\": lambda x: get_chat_history(memory)\n",
    "    }\n",
    "    | prompt\n",
    "    | groq_llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b05f11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_memory(question):\n",
    "    try:\n",
    "        # Get answer from RAG chain\n",
    "        answer = rag_chain.invoke(question)\n",
    "        \n",
    "        # Save to memory\n",
    "        memory.save_context(\n",
    "            {\"input\": question},\n",
    "            {\"answer\": answer}\n",
    "        )\n",
    "        \n",
    "        return answer\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error generating response: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f299c8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Lekki Bridge project is a 2.4-kilometer reinforced concrete bridge construction project along the Lekki-Epe Expressway coastal corridor. The goal of the project is to reduce traffic congestion and improve coastal connectivity as part of the Lagos State Infrastructure Development Initiative. The project involves a range of responsibilities, including detailed engineering design, site preparation, construction of the bridge foundation, erection of the superstructure, installation of drainage and safety systems, and more. The bridge will span from Admiralty Way Junction to Chevron Drive, crossing the tidal lagoon section. \n",
      "\n",
      "To determine if this project is a good fit for your company, I'd like to know more about your company's capabilities and experience with similar projects. What's your company's background in bridge construction, and have you worked on projects of this scale before?\n"
     ]
    }
   ],
   "source": [
    "response1 = chat_with_memory(\"What is the Lekki Bridge project about?\")\n",
    "print(response1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af3c1847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To be eligible to bid on the Lekki Bridge project, companies must meet two main sets of requirements: Company Registration Requirements and Technical Requirements.\n",
      "\n",
      "Under Company Registration Requirements, bidders must possess:\n",
      "1. A valid Corporate Affairs Commission (CAC) registration certificate\n",
      "2. A Tax Clearance Certificate for the current year (2025)\n",
      "3. Evidence of registration with the Federal Inland Revenue Service (FIRS)\n",
      "4. A VAT registration certificate\n",
      "5. A Pension Commission (PenCom) compliance certificate\n",
      "\n",
      "In terms of Technical Requirements, bidders must have:\n",
      "1. A minimum of 10 years of operational experience in civil engineering construction\n",
      "2. Successful completion of at least three bridge construction projects within the last 7 years\n",
      "\n",
      "These requirements are mandatory, and bidders must meet all of them to be considered for the contract award. The contract will be awarded to the bidder with the highest combined technical and financial score, provided they meet all the eligibility requirements and have an acceptable financial standing and integrity. \n",
      "\n",
      "To assess whether your company is eligible, can you tell me about your company's registration status and technical experience, particularly in bridge construction?\n"
     ]
    }
   ],
   "source": [
    "response2 = chat_with_memory(\"What are the key eligibility requirements for bidders?\")\n",
    "print(response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "545ddca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With the additional context information, I can now confirm that Elalan Construction Limited meets the requirements for the Lekki Bridge project.\n",
      "\n",
      "Firstly, regarding company registration, although the document does not explicitly mention their registration status, it can be inferred that Elalan Construction Limited is a registered company, as they have been operating since 2001 and have worked on significant projects, including the Third Mainland Bridge rehabilitation project.\n",
      "\n",
      "On the technical side, Elalan Construction Limited has demonstrated exceptional technical competence and project management skills, as evidenced by the formal feedback from the Federal Ministry of Works and Housing (FMWH) in October 2018. The feedback commends their proactive approach to traffic management and safety, and states that they would not hesitate to engage Elalan for future projects of similar scale and complexity.\n",
      "\n",
      "The Third Mainland Bridge rehabilitation project, which was completed 2 months ahead of schedule and within budget, demonstrates Elalan's technical competence and project management excellence. The project highlights include:\n",
      "\n",
      "* Contract Value: â‚¦2.8 billion\n",
      "* Duration: 18 months (Planned: 20 months)\n",
      "* Completion Status: 100%\n",
      "* Cost Performance: Within budget (0.8% under)\n",
      "* Quality Rating: Excellent (98.5% compliance)\n",
      "* Safety Record: Zero fatalities, LTIFR 0.08\n",
      "\n",
      "This experience meets the requirement for successful completion of at least three bridge construction projects within the last 7 years, as the Third Mainland Bridge rehabilitation project was completed in 2018.\n",
      "\n",
      "Additionally, Elalan Construction Limited has more than 10 years of operational experience in civil engineering construction, which meets the minimum experience requirement.\n",
      "\n",
      "Based on this information, I conclude that Elalan Construction Limited meets the eligibility requirements for the Lekki Bridge project, including company registration, technical competence, and experience with bridge construction projects.\n"
     ]
    }
   ],
   "source": [
    "response3 = chat_with_memory(\"Does Elalan Construction meet these requirements? Dont forget about the Third Mainland Bridge Project\")\n",
    "print(response3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (yRag)",
   "language": "python",
   "name": "yrag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
